{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras imports for the dataset and building our neural network\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "n_train, height, width = X_train.shape\n",
    "n_test, _, _ = X_test.shape\n",
    "\n",
    "n_train, n_test, height, width\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we have to preprocess the data into the right shape\n",
    "X_train = X_train.reshape(n_train, height, width, 1).astype('float32')\n",
    "X_test = X_test.reshape(n_test, height, width, 1).astype('float32')\n",
    "\n",
    "# normalize from [0, 255] to [0, 1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# numbers 0-9, so ten classes\n",
    "n_classes = 10\n",
    "\n",
    "# convert integer labels into one-hot vectors\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "# i.e. we will use a n_conv x n_conv filter\n",
    "n_conv = 3\n",
    "\n",
    "# pooling window size\n",
    "# i.e. we will use a n_pool x n_pool pooling window\n",
    "n_pool = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "15104/60000 [======>.......................] - ETA: 6:57 - loss: 0.5995 - acc: 0.8099"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(\n",
    "        n_filters, \n",
    "        kernel_size=(n_conv, n_conv),\n",
    "        # we have a 28x28 single channel (grayscale) image\n",
    "        # so the input shape should be (28, 28, 1)\n",
    "        input_shape=(height, width, 1)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# then we apply pooling to summarize the features\n",
    "# extracted thus far\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten the data for the 1D layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense(n_outputs)\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# the softmax output layer gives us a probablity for each class\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# how many examples to look at during each update step\n",
    "batch_size = 128\n",
    "\n",
    "# how many times to run through the full set of examples\n",
    "n_epochs = 1\n",
    "\n",
    "# the training may be slow depending on your computer\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# how'd we do?\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "\n",
    "x_sample = X_test[0].reshape(1,28,28,1)\n",
    "y_prob = model.predict(x_sample)[0]\n",
    "y_pred = y_prob.argmax()\n",
    "y_actual = y_test[0].argmax()\n",
    "\n",
    "print(\"probabilities: \", y_prob)\n",
    "print(\"predicted = %d, actual = %d\" % (y_pred, y_actual))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
